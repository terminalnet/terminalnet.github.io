---
layout: post
title: "IA não consegue identificar pessoas trans e não binárias"
categories: [ News ]
image: 'assets/images/ia.jpg'
---

A modelo Rain Dove está bebendo em um bar e precisa ir ao banheiro. Ao caminhar pelo corredor de acesso, uma câmera digitaliza o rosto dela para destrancar a porta do toalete de acordo com seu gênero. Que porta o rosto de Rain Dove destrancaria? Provavelmente a do banheiro masculino.

Uma pesquisa realizada pela Universidade do Colorado em Boulder, nos Estados Unidos, descobriu que os principais softwares de reconhecimento facial, baseados em inteligência artificial, não conseguem identificar pessoas trans e não binárias.

<!-- RETANGULO LARGO -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- Informat -->
<ins class="adsbygoogle"
style="display:block"
data-ad-client="ca-pub-2838251107855362"
data-ad-slot="2327980059"
data-ad-format="auto"
data-full-width-responsive="true"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>  

Enquanto homens e mulheres cisgêneros foram classificados com precisão em 98% dos casos, pessoas trans (que não se identificam com seu gênero de nascimento) foram categorizados de maneira errada em cerca de 30% das vezes. No caso dos não binários (que não se identificam como homem nem como mulher), a máquina errou todas as tentativas.

Para realizar a pesquisa foram coletadas 2.450 fotos de rostos no Instagram com as hashtags #woman, #man, #transwoman, #transman, #agenderqueer e #nonbinary. Depois de eliminados os registros em grupo ou com rostos meio ocultos, o que restou foi dividido em grupos de 350 imagens que foram usadas para testar os softwares de reconhecimento facial Rekognition (Amazon), Watson (IBM), Azure (Microsoft) e Clarifai.

<!-- RETANGULO LARGO 2 -->
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle"
style="display:block; text-align:center;"
data-ad-layout="in-article"
data-ad-format="fluid"
data-ad-client="ca-pub-2838251107855362"
data-ad-slot="8549252987"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>

![Rain Dove é a modelo americana não binária mais famosa da moda.](/assets/images/ia.jpg "Rain Dove é a modelo americana não binária mais famosa da moda. Fonte: Instagram/Rain Dove")
*Rain Dove é a modelo americana não binária mais famosa da moda. (Fonte: Instagram/Rain Dove)*

<!-- QUADRADO -->
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle"
style="display:inline-block;width:336px;height:280px"
data-ad-client="ca-pub-2838251107855362"
data-ad-slot="5351066970"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>

## Inteligência artificial replica preconceitos

Os pesquisadores acreditam que os algoritmos usam estereótipos ultrapassados, o que aumenta ainda mais as taxas de erro. Um exemplo veio da própria equipe: um dos pesquisadores, que tem cabelos longos, foi classificado como mulher por metade dos softwares.

Não só o gênero é mal interpretado: um estudo do MIT Media Lab divulgado em janeiro indica que o Rekognition identificou mulheres negras como homens em 30% das vezes que foi acionado. Enquanto falhas como essas não são corrigidas, o preconceito aparece nos lugares mais inusitados: em 2015, o Google Fotos, usando inteligência artificial, marcou selfies de usuários negros como imagens de gorilas.

<!-- MINI ANÚNCIO -->
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- Games Root -->
<ins class="adsbygoogle"
style="display:inline-block;width:336px;height:50px"
data-ad-client="ca-pub-2838251107855362"
data-ad-slot="5351066970"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>

Via: [Quartz](https://qz.com/1726806/facial-recognition-ai-from-amazon-microsoft-and-ibm-misidentifies-trans-and-non-binary-people/)
