I"È<p>A modelo Rain Dove est√° bebendo em um bar e precisa ir ao banheiro. Ao caminhar pelo corredor de acesso, uma c√¢mera digitaliza o rosto dela para destrancar a porta do toalete de acordo com seu g√™nero. Que porta o rosto de Rain Dove destrancaria? Provavelmente a do banheiro masculino.</p>

<p>Uma pesquisa realizada pela Universidade do Colorado em Boulder, nos Estados Unidos, descobriu que os principais softwares de reconhecimento facial, baseados em intelig√™ncia artificial, n√£o conseguem identificar pessoas trans e n√£o bin√°rias.</p>

<!-- RETANGULO LARGO -->
<script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- Informat -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-2838251107855362" data-ad-slot="2327980059" data-ad-format="auto" data-full-width-responsive="true"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></p>

<p>Enquanto homens e mulheres cisg√™neros foram classificados com precis√£o em 98% dos casos, pessoas trans (que n√£o se identificam com seu g√™nero de nascimento) foram categorizados de maneira errada em cerca de 30% das vezes. No caso dos n√£o bin√°rios (que n√£o se identificam como homem nem como mulher), a m√°quina errou todas as tentativas.</p>

<p>Para realizar a pesquisa foram coletadas 2.450 fotos de rostos no Instagram com as hashtags #woman, #man, #transwoman, #transman, #agenderqueer e #nonbinary. Depois de eliminados os registros em grupo ou com rostos meio ocultos, o que restou foi dividido em grupos de 350 imagens que foram usadas para testar os softwares de reconhecimento facial Rekognition (Amazon), Watson (IBM), Azure (Microsoft) e Clarifai.</p>

<!-- RETANGULO LARGO 2 -->
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<p><ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-2838251107855362" data-ad-slot="8549252987"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></p>

<p><img src="/assets/images/ia.jpg" alt="Rain Dove √© a modelo americana n√£o bin√°ria mais famosa da moda." title="Rain Dove √© a modelo americana n√£o bin√°ria mais famosa da moda. Fonte: Instagram/Rain Dove" />
<em>Rain Dove √© a modelo americana n√£o bin√°ria mais famosa da moda. (Fonte: Instagram/Rain Dove)</em></p>

<!-- QUADRADO -->
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<p><ins class="adsbygoogle" style="display:inline-block;width:336px;height:280px" data-ad-client="ca-pub-2838251107855362" data-ad-slot="5351066970"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></p>

<h2 id="intelig√™ncia-artificial-replica-preconceitos">Intelig√™ncia artificial replica preconceitos</h2>

<p>Os pesquisadores acreditam que os algoritmos usam estere√≥tipos ultrapassados, o que aumenta ainda mais as taxas de erro. Um exemplo veio da pr√≥pria equipe: um dos pesquisadores, que tem cabelos longos, foi classificado como mulher por metade dos softwares.</p>

<p>N√£o s√≥ o g√™nero √© mal interpretado: um estudo do MIT Media Lab divulgado em janeiro indica que o Rekognition identificou mulheres negras como homens em 30% das vezes que foi acionado. Enquanto falhas como essas n√£o s√£o corrigidas, o preconceito aparece nos lugares mais inusitados: em 2015, o Google Fotos, usando intelig√™ncia artificial, marcou selfies de usu√°rios negros como imagens de gorilas.</p>

<!-- MINI AN√öNCIO -->
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- Games Root -->
<p><ins class="adsbygoogle" style="display:inline-block;width:336px;height:50px" data-ad-client="ca-pub-2838251107855362" data-ad-slot="5351066970"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></p>

<p>Via <a href="https://qz.com/1726806/facial-recognition-ai-from-amazon-microsoft-and-ibm-misidentifies-trans-and-non-binary-people/">Quartz</a></p>
:ET